# AI関連年表

* IC: Image Classifiacation
* OD: Object Detection
* SS: Semantic Segmentation
* NLP: Natural Language Processing
* TS: Time Series
* Gen: Generation

|年|技術|IC|OD|SS|NLP|TS|Gen|関連情報|
|---|---|---|---|---|---|---|---|---|
|1958|パーセプトロン| :heavy_check_mark: |||| :heavy_check_mark: || [THE PERCEPTRON: A PROBABILISTIC MODEL FOR INFORMATION STORAGE AND ORGANIZATION IN THE BRAIN](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&rep=rep1&type=pdf)|
||ロジスティック回帰| :heavy_check_mark: |||| :heavy_check_mark: |||
|1963|サポートベクターマシン(SVM)| :heavy_check_mark: |||| :heavy_check_mark: |||
|1980|「強いAI・弱いAI」の概念の登場||||||||
|1986|RNN|||| :heavy_check_mark: | :heavy_check_mark: || [Backpropagation Through Time](http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Werbos.backprop.pdf) |
|1991|Python||||||||
|1997|LSTM|||| :heavy_check_mark: | :heavy_check_mark: || [LONG SHORT-TERM MEMORY](https://www.bioinf.jku.at/publications/older/2604.pdf)|
|1998|LeNet| :heavy_check_mark: |||||| [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) |
|2006|積層オートエンコーダ|||||| :heavy_check_mark: ||
|2012|AlexNet| :heavy_check_mark: |||||| [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) |
||Selective Search|| :heavy_check_mark: ||||| [Selective Search for Object Recognition](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) |
|2013|R-CNN|| :heavy_check_mark: | :heavy_check_mark: |||| [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524) |
|2014|VGG| :heavy_check_mark: |||||| [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) |
||GoogLeNet| :heavy_check_mark: |||||| [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) |
||GAN|||||| :heavy_check_mark: | [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) |
||GRU|||| :heavy_check_mark: | :heavy_check_mark: || [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555) |
||Seq2Seq|||| :heavy_check_mark: | :heavy_check_mark: || [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) |
||DPMs|| :heavy_check_mark: ||||| [Deformable Part Models are Convolutional Neural Networks](https://arxiv.org/abs/1409.5403) |
|2015|ResNet| :heavy_check_mark: |||||| [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) |
||Attention|||| :heavy_check_mark: | :heavy_check_mark: || [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf) |
||Fast R-CNN|| :heavy_check_mark: | :heavy_check_mark: |||| [Fast R-CNN](https://arxiv.org/abs/1504.08083) |
||Faster R-CNN|| :heavy_check_mark: | :heavy_check_mark: |||| [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) |
||YOLO|| :heavy_check_mark: ||||| [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) |
||SSD|| :heavy_check_mark: ||||| [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) |
|2016|SqueezeNet| :heavy_check_mark: |||||| [SQUEEZENET](https://arxiv.org/pdf/1602.07360.pdf) |
||R-FCN|| :heavy_check_mark: ||||| [R-FCN: Object Detection via Region-based Fully Convolutional Networks](https://arxiv.org/abs/1605.06409) |
||YOLO9000(YOLOv2)|| :heavy_check_mark: ||||| [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) |
|2017|MobileNet(v1)| :heavy_check_mark: |||||| [MobileNets](https://arxiv.org/pdf/1704.04861.pdf) |
||Transformer|||| :heavy_check_mark: | :heavy_check_mark: || [Attention Is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) |
||Mask R-CNN|| :heavy_check_mark: | :heavy_check_mark: |||| [Mask R-CNN](https://arxiv.org/abs/1703.06870) |
|2018|MobileNet(v2)| :heavy_check_mark: |||||| [MobileNetV2](https://arxiv.org/pdf/1801.04381v3.pdf) |
||BERT|||| :heavy_check_mark: ||| [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) |
||YOLOv3|| :heavy_check_mark: ||||| [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767) |
||M2Det|| :heavy_check_mark: ||||| [A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network](https://arxiv.org/abs/1811.04533) |
|2019|MobileNet(v3)| :heavy_check_mark: |||||| [Searching for MobileNetV3](https://arxiv.org/pdf/1905.02244.pdf) |
||GPT-2|||| :heavy_check_mark: ||| [Hello, It's GPT-2 -- How Can I Help You? Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems](https://arxiv.org/abs/1907.05774) |
||T5|||| :heavy_check_mark: ||| [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) |
||EfficientNet| :heavy_check_mark: |||||| [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946) |
||EfficientDet|| :heavy_check_mark: ||||| [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) |
|2020|GPT-3|||| :heavy_check_mark: ||| [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) |
||YOLOv4|| :heavy_check_mark: ||||| [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934) |
||DETR|| :heavy_check_mark: ||||| [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) |
||DRN|| :heavy_check_mark: ||||| [Dynamic Refinement Network for Oriented and Densely Packed Object Detection](https://arxiv.org/abs/2005.09973) |
||Beta R-CNN|| :heavy_check_mark: ||||| [Beta R-CNN: Looking into Pedestrian Detection from Another Perspective](https://papers.nips.cc/paper/2020/file/e6b4b2a746ed40e1af829d1fa82daa10-Paper.pdf) |
|2021|DALL-E|||| :heavy_check_mark: || :heavy_check_mark: | [Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092) |
||EfficientNetV2| :heavy_check_mark: |||||| [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298) |
||Swin Transformer|| :heavy_check_mark: | :heavy_check_mark: |||| [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) |
||UniverseNet|| :heavy_check_mark: ||||| [USB: Universal-Scale Object Detection Benchmark](https://arxiv.org/abs/2103.14027) |

# 参考

* [【資格対策にも！】ダートマス会議からシンギュラリティまでAIの歴史を年表でおさらい](https://ainow.ai/2020/03/25/193030/)
* [深層学習／GoogLeNet, ResNet](https://qiita.com/jun40vn/items/5ac97a6f1d8f82a49194)
* [MobileNet(v1,v2,v3)を簡単に解説してみた](https://qiita.com/omiita/items/77dadd5a7b16a104df83)
* [[Survey]SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size](https://qiita.com/supersaiakujin/items/ece1e20ca4073e77bed7)
* [今度こそわかるぞRNN, LSTM編](https://qiita.com/kazukiii/items/df809d6cd5d7d1f57be3)
* [回帰型ニューラルネットワーク](https://ja.wikipedia.org/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)
* [RNNからTransformerまでの歴史を辿る ～DNNを使ったNLPを浅く広く勉強～](https://aru47.hatenablog.com/entry/2020/08/18/175711)
* [Recurrent Neural Networkとは何か、他のニューラルネットワークと何が違うのか](https://www.atmarkit.co.jp/ait/articles/1608/26/news011.html#03)
* [【論文シリーズ】新しいRNNの学習方法（Hessian FreeとRBM利用）](https://qiita.com/To_Murakami/items/d32ed128640ebd18b977)
* [Recurrent Neural Networks (1) – RNN への序説 （翻訳/要約）](https://tensorflow.classcat.com/2016/03/17/introduction-to-rnn/)
* [Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)
* [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0)
* [ディープラーニングは、時系列予測でも最強なのか？　～RNNと従来手法との対比から見える使いどころ～](https://www.sas.com/content/dam/SAS/documents/marketing-whitepapers-ebooks/sas-whitepapers/ja/viya-recurrent-neural-network.pdf)
* [わかるLSTM ～ 最近の動向と共に](https://qiita.com/t_Signull/items/21b82be280b46f467d1b)
* [複数入力を用いたRecurrent Neural Networkに基づく時系列予測](https://www.ieice.org/publications/conference-FIT-DVDs/FIT2019/data/pdf/CF-001.pdf)
* [自然言語処理の深層学習モデル](https://note.com/npaka/n/ne39e1f8d2d89)
* [【論文】"Attention is all you need"の解説](https://www.acceluniverse.com/blog/developers/2019/08/attention.html)
* [DALL-E: Creating Images from Text](https://openai.com/blog/dall-e/)
* [Recurrent Neural Networks](https://www.cs.ubc.ca/labs/lci/mlrg/slides/rnn.pdf)
* [画像分類や物体検出の学習に必要なモデル一覧](https://tomomai.com/python-model/)
* [2021年最強になるか！？最新の画像認識モデルEfficientNetV2を解説](https://qiita.com/omiita/items/1d96eae2b15e49235110)
* [[DL輪読会]EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://www.slideshare.net/DeepLearningJP2016/dlefficientnet-rethinking-model-scaling-for-convolutional-neural-networks)
* [最新のRegion CNN(R-CNN)を用いた物体検出入門 ~物体検出とは? R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN~](https://qiita.com/arutema47/items/8ff629a1516f7fd485f9)
* [What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)?](https://jonathan-hui.medium.com/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9)
* [【物体検出手法の歴史 : YOLOの紹介】](https://qiita.com/cv_carnavi/items/68dcda71e90321574a2b)
* [SSD:Single Shot Multibox Detector](https://qiita.com/de0ta/items/1ae60878c0e177fc7a3a)
* [Transformerを採用した最新の物体検出手法「DETR」](https://club.informatix.co.jp/?p=1265)
* [密集と任意方向に強い物体検出手法登場！](https://ai-scholar.tech/articles/object-detection/dynamic_refinement)
* [最新最強の物体検出技術M2Det](https://qiita.com/kzykmyzw/items/1831f70dcade04db2210)
