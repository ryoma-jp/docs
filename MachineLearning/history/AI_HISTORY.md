# AI関連年表

* IC: Image Classifiacation
* OD: Object Detection
* SS: Semantic Segmentation
* NLP: Natural Language Processing
* TS: Time Series
* Gen: Generation

|年|技術|IC|OD|SS|NLP|TS|Gen|関連情報|
|---|---|---|---|---|---|---|---|---|
|1958|パーセプトロン| :heavy_check_mark: |||| :heavy_check_mark: || [THE PERCEPTRON: A PROBABILISTIC MODEL FOR INFORMATION STORAGE AND ORGANIZATION IN THE BRAIN](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&rep=rep1&type=pdf)|
||ロジスティック回帰| :heavy_check_mark: |||| :heavy_check_mark: |||
|1963|サポートベクターマシン(SVM)| :heavy_check_mark: |||| :heavy_check_mark: |||
|1980|「強いAI・弱いAI」の概念の登場||||||||
|1986|RNN|||| :heavy_check_mark: | :heavy_check_mark: || [Backpropagation Through Time](http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Werbos.backprop.pdf) |
|1991|Python||||||||
|1995|LSTM|||| :heavy_check_mark: | :heavy_check_mark: || [LSTM](https://arxiv.org/pdf/1503.04069.pdf)|
|1998|LeNet| :heavy_check_mark: |||||| [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) |
|2006|積層オートエンコーダ|||||| :heavy_check_mark: ||
|2012|AlexNet| :heavy_check_mark: |||||| [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) |
|2014|VGG| :heavy_check_mark: |||||| [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) |
||GoogLeNet| :heavy_check_mark: |||||| [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) |
||GAN|||||| :heavy_check_mark: | [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) |
||GRU|||| :heavy_check_mark: | :heavy_check_mark: || [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555) |
||Seq2Seq|||| :heavy_check_mark: | :heavy_check_mark: || [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) |
|2015|ResNet| :heavy_check_mark: |||||| [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) |
||Attention|||| :heavy_check_mark: | :heavy_check_mark: || [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf) |
|2016|SqueezeNet| :heavy_check_mark: |||||| [SQUEEZENET](https://arxiv.org/pdf/1602.07360.pdf) |
|2017|MobileNet(v1)| :heavy_check_mark: |||||| [MobileNets](https://arxiv.org/pdf/1704.04861.pdf) |
||Transformer|||| :heavy_check_mark: | :heavy_check_mark: || [Attention Is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) |
|2018|MobileNet(v2)| :heavy_check_mark: |||||| [MobileNetV2](https://arxiv.org/pdf/1801.04381v3.pdf) |
||BERT|||| :heavy_check_mark: ||| [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) |
|2019|MobileNet(v3)| :heavy_check_mark: |||||| [Searching for MobileNetV3](https://arxiv.org/pdf/1905.02244.pdf) |
||GPT-2|||| :heavy_check_mark: ||| [Hello, It's GPT-2 -- How Can I Help You? Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems](https://arxiv.org/abs/1907.05774) |
||T5|||| :heavy_check_mark: ||| [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) |
|2020|GPT-3|||| :heavy_check_mark: ||| [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) |
|2021|DALL-E|||| :heavy_check_mark: || :heavy_check_mark: | [Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092) |


# 参考

* [【資格対策にも！】ダートマス会議からシンギュラリティまでAIの歴史を年表でおさらい](https://ainow.ai/2020/03/25/193030/)
* [深層学習／GoogLeNet, ResNet](https://qiita.com/jun40vn/items/5ac97a6f1d8f82a49194)
* [MobileNet(v1,v2,v3)を簡単に解説してみた](https://qiita.com/omiita/items/77dadd5a7b16a104df83)
* [[Survey]SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size](https://qiita.com/supersaiakujin/items/ece1e20ca4073e77bed7)
* [今度こそわかるぞRNN, LSTM編](https://qiita.com/kazukiii/items/df809d6cd5d7d1f57be3)
* [回帰型ニューラルネットワーク](https://ja.wikipedia.org/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)
* [RNNからTransformerまでの歴史を辿る ～DNNを使ったNLPを浅く広く勉強～](https://aru47.hatenablog.com/entry/2020/08/18/175711)
* [Recurrent Neural Networkとは何か、他のニューラルネットワークと何が違うのか](https://www.atmarkit.co.jp/ait/articles/1608/26/news011.html#03)
* [【論文シリーズ】新しいRNNの学習方法（Hessian FreeとRBM利用）](https://qiita.com/To_Murakami/items/d32ed128640ebd18b977)
* [Recurrent Neural Networks (1) – RNN への序説 （翻訳/要約）](https://tensorflow.classcat.com/2016/03/17/introduction-to-rnn/)
* [Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)
* [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0)
* [ディープラーニングは、時系列予測でも最強なのか？　～RNNと従来手法との対比から見える使いどころ～](https://www.sas.com/content/dam/SAS/documents/marketing-whitepapers-ebooks/sas-whitepapers/ja/viya-recurrent-neural-network.pdf)
* [わかるLSTM ～ 最近の動向と共に](https://qiita.com/t_Signull/items/21b82be280b46f467d1b)
* [複数入力を用いたRecurrent Neural Networkに基づく時系列予測](https://www.ieice.org/publications/conference-FIT-DVDs/FIT2019/data/pdf/CF-001.pdf)
* [自然言語処理の深層学習モデル](https://note.com/npaka/n/ne39e1f8d2d89)
* [【論文】"Attention is all you need"の解説](https://www.acceluniverse.com/blog/developers/2019/08/attention.html)
* [DALL-E: Creating Images from Text](https://openai.com/blog/dall-e/)
* [Recurrent Neural Networks](https://www.cs.ubc.ca/labs/lci/mlrg/slides/rnn.pdf)
* [画像分類や物体検出の学習に必要なモデル一覧](https://tomomai.com/python-model/)
